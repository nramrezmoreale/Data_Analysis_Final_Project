# -*- coding: utf-8 -*-
"""tp_final_analisisdedatos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DmkUNksoQCXn92btP77uT0mor3EyZLMD

CARGO LOS CSV  CON EL CODIGO A CONTINUACION O LOS ARRASTRO DE FORMA LOCAL PERO DESAPARECEN LUEGO DE FINALIZADA LA SESION
"""

from google.colab import files
uploaded = files.upload()

import os
#verifico que archivos tiene mi sesion
print(os.listdir())

"""LEVANTO CSV A DATAFRAME SEPARADOS POR PUNTO Y COMA"""

#IMPORTO LIBRERIA PANDAS
import pandas as pd

# Cargar el CSV
# low_memory: Esto permite a pandas usar más memoria al procesar el archivo
data_2019 = pd.read_csv('2019.csv' ,sep=';', low_memory=False )
# Cargar el CSV
data_2020 = pd.read_csv('2020.csv' ,sep=';', low_memory=False )
# Cargar el CSV
data_2021 = pd.read_csv('2021.csv' ,sep=',', low_memory=False )
# Cargar el CSV
data_2022 = pd.read_csv('2022.csv' ,sep=';' , low_memory=False)
# Cargar el CSV
data_2023 = pd.read_csv('2023.csv' ,sep=';', low_memory=False )


#verifico que se carguen bien los dataframe
print(data_2019.head(5))
print(data_2020.head(5))
print(data_2021.head(5))
print(data_2022.head(5))
print(data_2023.head(5))

#verifico columnas de dataframe
print(data_2019.columns)
print(data_2020.columns)
print(data_2021.columns)
print(data_2022.columns)
print(data_2023.columns)

"""LOS ARCHIVOS POSEEN LAS MISMAS COLUMNAS CON VARIANTES DE NOMBRES , PERO TODAS RESPETAN LA POSICION DE LOS DATOS DONDE SE ENCUENTRAN .
SE VA A REALIZAR UN APPEND PARA TENER TODOS LOS DATOS EN UN DATAFRAME Y EN UN CSV
"""

# Diccionario de mapeo para renombrar las columnas
column_mapping = {
    'Fecha': 'Fecha_utc',
    'Hora UTC': 'Hora_utc',
    'Clase de vuelos (todos los vuelos)': 'Clase_vuelos',
    'Clasificacion Vuelo': 'Clasificacion_vuelo',
    'Tipo Movimiento': 'Tipo_movimiento',
    'Tipo de Movimiento': 'Tipo_movimiento',
    'Aeropuerto': 'Aeropuerto',
    'Origen/Destino': 'Origen_destino',
    'Aerolinea Nombre': 'Aerolinea_nombre',
    'Aeronave': 'Aeronave',
    'Pasajeros': 'Pasajeros',
    'PAX': 'Pax',
    'Calidad del dato': 'Calidad_del_dato',
    'Fecha UTC': 'Fecha_utc',
    'Origen / Destino': 'Origen_destino',
    'Calidad dato': 'Calidad_del_dato',
    'Clasificación Vuelo': 'Clasificacion_vuelo',
    'Clase de Vuelo (todos los vuelos)': 'Clase_vuelos'


}

print ("columnas 2019")
data_2019.rename(columns=column_mapping, inplace=True)
print(data_2019.columns)

print ("columnas 2020")
data_2020.rename(columns=column_mapping, inplace=True)
print(data_2020.columns)


print ("columnas 2021")
data_2021.rename(columns=column_mapping, inplace=True)
print(data_2021.columns)


print ("columnas 2022")
data_2022.rename(columns=column_mapping, inplace=True)
print(data_2022.columns)

print ("columnas 2023")
data_2023.rename(columns=column_mapping, inplace=True)
print(data_2023.columns)

# Hacer el append de todos los DataFrames
datos_combinados = pd.concat([data_2019,data_2020, data_2021, data_2022,data_2023], ignore_index=True)


print(datos_combinados.head(5))
print(datos_combinados.columns)

"""AHORA QUE ESTAN LOS CAMPOS ESTANDARIZADOS Y TODO EN UN SOLO DATAFRAME SE VA A EXPORTAR A CSV DELIMITADO POR PUNTO Y COMA

NORMALIZAR CAMPO FECHA YA QUE SE ENCUENTRA EN UTC . NECESITAMOS PASARLO A UTC-3 QUE ES EL QUE SE MANEJA EN ARGENTINA PARA LUEGO HACER ANALISIS
"""

# Paso 1: Asegurarse de que todas las horas tengan formato HH:MM (remover segundos si están presentes)
datos_combinados['Hora_utc'] = datos_combinados['Hora_utc'].apply(lambda x: x[:5] if len(x) >= 5 else x)

# Paso 2: Combinar Fecha y Hora en un solo campo de tipo datetime en UTC
datos_combinados['FechaHora_utc'] = pd.to_datetime(datos_combinados['Fecha_utc'] + ' ' + datos_combinados['Hora_utc'], utc=True, dayfirst=True, errors='coerce')

# Paso 3: Convertir de UTC a UTC-3 (Hora de Argentina)
datos_combinados['FechaHora_arg'] = datos_combinados['FechaHora_utc'].dt.tz_convert('America/Argentina/Buenos_Aires')

# Paso 4: Separar en Fecha y Hora en la zona horaria de Argentina, sin segundos
datos_combinados['Fecha_arg'] = datos_combinados['FechaHora_arg'].dt.strftime('%d/%m/%Y')  # Formato dd/mm/yyyy
datos_combinados['Hora_arg'] = datos_combinados['FechaHora_arg'].dt.strftime('%H:%M')  # Formato sin segundos

print(datos_combinados[['Fecha_utc', 'Hora_utc', 'FechaHora_utc', 'FechaHora_arg', 'Fecha_arg', 'Hora_arg']])

"""SIGUIENTE PASO ESTANDARIZAR Y CONVERTIR DATOS DE LOS CAMPOS QUE SE VAN A UTILIZAR PARA HACER ANALISIS"""

# Paso 1: Obtener los valores únicos
print("Valores únicos en 'clase_vuelos':", datos_combinados['Clase_vuelos'].unique())

# Paso 2: Definir un mapeo de estandarización
clase_vuelos_mapping = {
    'REGULAR': 'REGULAR',
    'Regular': 'Regular',

    'VUELOS PRIVADOS NACIONALES': 'VUELOS PRIVADOS NACIONALES',
    'Vuelo Privado con Matrícula Nacional': 'VUELOS PRIVADOS NACIONALES',

    'VUELOS OFICIALES NACIONALES': 'VUELOS OFICIALES NACIONALES',
    'Vuelo Oficial Nacional': 'VUELOS OFICIALES NACIONALES',

    'NO REGULAR': 'REGULAR',
    'No Regular': 'NO REGULAR',

    'VUELOS PRIVADO CON MATRICULA EXTRANJERA': 'VUELOS PRIVADO CON MATRICULA EXTRANJERA',
    'Vuelo Privado con Matrícula Extranjera': 'VUELOS PRIVADO CON MATRICULA EXTRANJERA',

    'VUELOS DE ADIESTRAMIENTO': 'VUELOS DE ADIESTRAMIENTO',
    'Vuelo de Adiestramiento': 'VUELOS DE ADIESTRAMIENTO',

    'VUELOS ESCUELA': 'VUELOS ESCUELA',
    'Vuelo Escuela': 'VUELOS ESCUELA',

    'VUELOS OFICIALES EXTRANJEROS': 'VUELOS OFICIALES EXTRANJEROS',
    'Vuelo Oficial Extranjero': 'VUELOS OFICIALES EXTRANJEROS',

    'TRABAJO AEREO': 'TRABAJO AEREO',
    'Trabajo Aéreo': 'TRABAJO AEREO',

    'ESCUELA (NO VIGENTE)': 'ESCUELA (NO VIGENTE)'
}



# Paso 3: Aplicar el mapeo a la columna
datos_combinados['Clase_vuelos'] = datos_combinados['Clase_vuelos'].replace(clase_vuelos_mapping)

# Paso 4: Convertir a mayúsculas (en caso de que no se haya hecho)
datos_combinados['Clase_vuelos'] = datos_combinados['Clase_vuelos'].str.upper()



# Mostrar el DataFrame estandarizado
#print("\nDataFrame estandarizado:\n", datos_combinados)
print("Valores únicos en 'clase_vuelos':", datos_combinados['Clase_vuelos'].unique())


#clasificacion vuelos
print("Valores únicos en 'Clasificacion_vuelo':", datos_combinados['Clasificacion_vuelo'].unique())

# Por ejemplo para 'clasificacion_vuelos'
clasificacion_mapping = {
    'Doméstico': 'DOMESTICO',
    'Internacional': 'INTERNACIONAL',  # Corrigiendo acento
    'Dom': 'DOMESTICO',
    'Inter': 'INTERNACIONAL'
}

datos_combinados['Clasificacion_vuelo'] = datos_combinados['Clasificacion_vuelo'].replace(clasificacion_mapping).str.upper()

datos_combinados['Clasificacion_vuelo'] = datos_combinados['Clasificacion_vuelo'].str.upper()
print("Valores únicos en 'Clasificacion_vuelo':", datos_combinados['Clasificacion_vuelo'].unique())




#pasar a mayuscula

datos_combinados['Tipo_movimiento'] = datos_combinados['Tipo_movimiento'].str.upper()
print("Valores únicos en 'Tipo_movimiento':", datos_combinados['Tipo_movimiento'].unique())

#hay 3 registros que estan en nan nomas

# Mostrar el DataFrame final
#print("\nDataFrame final:\n", datos_combinados)

"""PARSEAR A NUMERICO EL CAMPO NUMERICO"""

# Utiliza errors='coerce' para convertir valores no válidos en NaN
datos_combinados['Pasajeros'] = pd.to_numeric(datos_combinados['Pasajeros'], errors='coerce')

# Si deseas convertir NaN a 0 (o a otro valor), puedes usar fillna
datos_combinados['Pasajeros'] = datos_combinados['Pasajeros'].fillna(0).astype(int)

"""MOSTRAR TODOS LOS TIPOS DE DATOS DE LOS CAMPOS"""

# También puedes mostrar el tipo de dato de todo el DataFrame
tipos_datos_completos = datos_combinados.dtypes

# Imprimir los resultados

print("\nTipos de datos de todas las columnas:\n", tipos_datos_completos)

# Limpiar espacios en blanco
datos_combinados['Fecha_utc'] = datos_combinados['Fecha_utc'].str.strip()
datos_combinados['Hora_utc'] = datos_combinados['Hora_utc'].str.strip()
datos_combinados['Fecha_arg'] = datos_combinados['Fecha_arg'].str.strip()
# Paso 1: Convertir Fecha_utc a formato DD/MM/AAAA
datos_combinados['Fecha_utc'] = pd.to_datetime(datos_combinados['Fecha_utc'], dayfirst=True, errors='coerce').dt.strftime('%d/%m/%Y')

# Paso 2: Convertir Hora_utc a formato HH:MM
datos_combinados['Hora_utc'] = pd.to_datetime(datos_combinados['Hora_utc'], format='%H:%M', errors='coerce').dt.strftime('%H:%M')

# Paso 4: Convertir Fecha_arg a formato DD/MM/AAAA
datos_combinados['Fecha_arg'] = pd.to_datetime(datos_combinados['Fecha_arg'], errors='coerce', dayfirst=True)
datos_combinados['Fecha_arg'] = datos_combinados['Fecha_arg'].dt.strftime('%d/%m/%Y')

# Mostrar el tipo de dato actualizado
print(datos_combinados.dtypes)

"""CONVERTIR TIPOS DE DATOS DE LOS CAMPOS"""

# Estandarización de la columna 'Clasificacion_vuelo'
datos_combinados['Clasificacion_vuelo'] = datos_combinados['Clasificacion_vuelo'].str.strip().str.upper()

# Estandarización de la columna 'Tipo_movimiento'
datos_combinados['Tipo_movimiento'] = datos_combinados['Tipo_movimiento'].str.strip().str.upper()

# Estandarización de la columna 'Aeropuerto'
datos_combinados['Aeropuerto'] = datos_combinados['Aeropuerto'].str.strip().str.upper()

# Estandarización de la columna 'Origen_destino'
datos_combinados['Origen_destino'] = datos_combinados['Origen_destino'].str.strip().str.upper()

# Estandarización de la columna 'Aerolinea_nombre'
datos_combinados['Aerolinea_nombre'] = datos_combinados['Aerolinea_nombre'].str.strip().str.upper()

# Estandarización de la columna 'Aeronave'
datos_combinados['Aeronave'] = datos_combinados['Aeronave'].str.strip().str.upper()

# Estandarización de la columna 'Pax'
datos_combinados['Pax'] = datos_combinados['Pax'].str.strip().str.upper()

# Estandarización de la columna 'Calidad_del_dato'
datos_combinados['Calidad_del_dato'] = datos_combinados['Calidad_del_dato'].str.strip().str.upper()


# Verificar los tipos de datos
print(datos_combinados.dtypes)

print(datos_combinados.head())

print("Valores únicos en 'Aerolinea_nombre':", datos_combinados['Aerolinea_nombre'].unique())

# Imprimir todos los valores únicos de 'Aerolinea_nombre' sin abreviación
##aerolineas_unicas = datos_combinados['Aerolinea_nombre'].unique()
####print("Valores únicos en 'Aerolinea_nombre':", list(aerolineas_unicas))



# Usar pd.Series para una mejor visualización
##print(pd.Series(aerolineas_unicas).to_string(index=False))

!pip install babel


from babel.dates import format_datetime


# Asegúrate de que 'Fecha_arg' sea un objeto datetime
datos_combinados['Fecha_arg'] = pd.to_datetime(datos_combinados['Fecha_arg'], format='%d/%m/%Y')

# Crear una columna con el nombre del día en español
datos_combinados['Dia'] = datos_combinados['Fecha_arg'].apply(lambda x: format_datetime(x, 'EEEE', locale='es_ES'))

# Extraer el año para cada registro
datos_combinados['Anio'] = datos_combinados['Fecha_arg'].dt.year

# Crear una tabla de conteo para las horas y días
conteo = datos_combinados.groupby(['Anio', 'Dia', 'Hora_arg']).size().reset_index(name='Conteo')

print (datos_combinados.head())



# Mostrar la cantidad de registros (filas)
print("Cantidad de registros:", datos_combinados.shape[0])

#Filtrar los registros donde Clase_vuelos sea igual a 'REGULAR'
datos_combinados = datos_combinados[datos_combinados['Clase_vuelos'] == 'REGULAR']

print("Cantidad de registros:", datos_combinados.shape[0])

# Filtrar los registros donde Pasajeros no sea igual a 0
datos_combinados = datos_combinados[datos_combinados['Pasajeros'] != 0]

print("Cantidad de registros:", datos_combinados.shape[0])

"""HACER MERGE CON ID DE DESTINO Y ID"""

# Exporta a CSV con punto y coma como delimitador
datos_combinados.to_csv('vuelos_bd_total.csv', sep=';', index=False, encoding='utf-8')